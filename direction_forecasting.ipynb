{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    " #!wget http://your_domain/klines_1m_BTC_USDT.parquet"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ],
   "metadata": {
    "id": "-rulr6-1DFwr",
    "ExecuteTime": {
     "start_time": "2025-04-10T00:15:20.062825Z",
     "end_time": "2025-04-10T00:15:20.068715Z"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df = pd.read_parquet('klines_5m_BTC_USDT.parquet')\n",
    "df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2025-04-10T00:17:30.781389Z",
     "end_time": "2025-04-10T00:17:30.840357Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df = df.resample('30min').apply({\n",
    "    'open': 'first',\n",
    "    'close': 'last',\n",
    "    'low': 'min',\n",
    "    'high': 'max',\n",
    "})\n",
    "df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2025-04-10T00:17:34.522856Z",
     "end_time": "2025-04-10T00:17:34.562178Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df['open'].shift(0)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2025-04-10T11:02:33.216970Z",
     "end_time": "2025-04-10T11:02:33.236865Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Look at the change between open and close of a candle, normalized by the average price of btc at this time\n",
    "data = 2 * (df['close'] - df['open']) / (df['close'] + df['open'])\n",
    "sns.histplot(data, kde=True).set(xlim=(-0.02, 0.02))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2025-04-10T00:17:42.113308Z",
     "end_time": "2025-04-10T00:17:42.771068Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "delta_price = df['close'] - df['close'].shift(1)\n",
    "direction = (delta_price > 0) * 1.0 - (delta_price < 0) * 1.0\n",
    "direction"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2025-04-10T14:02:24.783840Z",
     "end_time": "2025-04-10T14:02:24.810561Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.scatter(direction.iloc[:250].index, direction.iloc[:250])\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2025-04-10T14:02:25.010502Z",
     "end_time": "2025-04-10T14:02:25.221266Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "price = (df['close'] - df['close'].shift(1)) / df['close']\n",
    "price = price.bfill()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2025-04-10T14:04:59.023854Z",
     "end_time": "2025-04-10T14:04:59.029217Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Pytorch"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2025-04-10T14:05:00.544885Z",
     "end_time": "2025-04-10T14:05:00.550473Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "SEQ_LEN = 512\n",
    "split_date = '2024-01-01'\n",
    "\n",
    "# Ensure alignment\n",
    "assert price.index.equals(direction.index)\n",
    "\n",
    "# Split by date\n",
    "train_mask = price.index < split_date\n",
    "val_mask = price.index >= split_date\n",
    "\n",
    "price_train, price_val = price[train_mask], price[val_mask]\n",
    "dir_train, dir_val = direction[train_mask], direction[val_mask]\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2025-04-10T14:05:01.001739Z",
     "end_time": "2025-04-10T14:05:01.009211Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class PriceToDirectionDataset(Dataset):\n",
    "    def __init__(self, price_series, direction_series, seq_len=512):\n",
    "        self.prices = price_series.values.astype(np.float32)\n",
    "        self.directions = direction_series.values.astype(np.float32)\n",
    "        self.seq_len = seq_len\n",
    "\n",
    "        assert len(self.prices) == len(self.directions)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.prices) - self.seq_len\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x = self.prices[idx:idx + self.seq_len]\n",
    "        y = self.directions[idx + self.seq_len]\n",
    "        return torch.tensor(x).unsqueeze(-1), torch.tensor([y])\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2025-04-10T14:05:01.349404Z",
     "end_time": "2025-04-10T14:05:01.356530Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_dataset = PriceToDirectionDataset(price_train, dir_train, seq_len=SEQ_LEN)\n",
    "val_dataset = PriceToDirectionDataset(price_val, dir_val, seq_len=SEQ_LEN)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=64)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2025-04-10T14:05:01.871024Z",
     "end_time": "2025-04-10T14:05:01.877345Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class Forecast(nn.Module):\n",
    "    \"\"\"\n",
    "    GRU-based sequence model for binary classification of time series direction.\n",
    "\n",
    "    Given a sequence of prices (or features), the model outputs two scores (logits)\n",
    "    at each time step, representing unnormalized probabilities for 'up' and 'down' directions.\n",
    "\n",
    "    Final softmax is applied externally (e.g., in the loss function like nn.CrossEntropyLoss).\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, input_dim=1, hidden_dim=16, num_layers=1):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            input_dim (int): Number of input features per time step.\n",
    "            hidden_dim (int): Size of the GRU hidden state.\n",
    "            num_layers (int): Number of stacked GRU layers.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.gru = nn.GRU(input_dim, hidden_dim, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, 2)  # Output logits for two classes: [up, down]\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Forward pass through the model.\n",
    "\n",
    "        Args:\n",
    "            x (Tensor): Input tensor of shape (batch, sequence_length, input_dim)\n",
    "\n",
    "        Returns:\n",
    "            Tensor: Output logits of shape (batch, sequence_length, 2)\n",
    "                    representing scores for each class at each time step.\n",
    "        \"\"\"\n",
    "        out, _ = self.gru(x)     # out shape: (batch, seq_len, hidden_dim)\n",
    "        out = self.fc(out)       # out shape: (batch, seq_len, 2)\n",
    "        return out\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2025-04-10T14:13:44.933052Z",
     "end_time": "2025-04-10T14:13:44.986312Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Generate some noise and run it through the model to confirm the proper implementation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "x = torch.randn(2, 512, 1)  # batch of 2, seq len 512\n",
    "model = Forecast()\n",
    "y = model(x)\n",
    "print(y)  # should be (2, 512, 1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2025-04-10T14:13:54.447716Z",
     "end_time": "2025-04-10T14:13:54.482307Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Training"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "class Trainer:\n",
    "    def __init__(self, model, train_loader, val_loader, lr=1e-3):\n",
    "        \"\"\"\n",
    "        Trainer for binary classification (up/down) based on GRU outputs.\n",
    "\n",
    "        Model output: logits of shape (batch, time, 2)\n",
    "        Target: float labels → mapped to class index:\n",
    "            y >= 0 → 0 (up)\n",
    "            y <  0 → 1 (down)\n",
    "        \"\"\"\n",
    "        self.model = model.to(device)\n",
    "        self.train_loader = train_loader\n",
    "        self.val_loader = val_loader\n",
    "        self.opt = torch.optim.Adam(self.model.parameters(), lr=lr)\n",
    "        self.loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "        self.train_loss_steps = []\n",
    "        self.val_loss_checkpoints = []\n",
    "\n",
    "    def train(self, epochs=10):\n",
    "        for epoch in range(epochs):\n",
    "            self.model.train()\n",
    "            pbar = tqdm(self.train_loader, desc=f\"Epoch {epoch+1}\", leave=False)\n",
    "            val_check_interval = max(1, len(self.train_loader) // 10)\n",
    "\n",
    "            for i, (x, y) in enumerate(pbar):\n",
    "                x, y = x.to(device), y.to(device)\n",
    "\n",
    "                # Convert float targets to class indices: y >= 0 → 0, y < 0 → 1\n",
    "                y_class = (y.squeeze() < 0).long()  # True (down) → 1, False (up) → 0\n",
    "\n",
    "                logits = self.model(x)[:, -1, :]  # shape: (batch, 2)\n",
    "                loss = self.loss_fn(logits, y_class)\n",
    "\n",
    "                assert not torch.isnan(x).any().any()\n",
    "\n",
    "                self.opt.zero_grad()\n",
    "                loss.backward()\n",
    "                self.opt.step()\n",
    "\n",
    "                self.train_loss_steps.append(loss.item())\n",
    "\n",
    "                if (i + 1) % val_check_interval == 0:\n",
    "                    val_loss = self.evaluate()\n",
    "                    self.val_loss_checkpoints.append(val_loss)\n",
    "                    pbar.set_postfix(train_loss=loss.item(), val_loss=val_loss)\n",
    "                else:\n",
    "                    pbar.set_postfix(train_loss=loss.item())\n",
    "\n",
    "    def evaluate(self):\n",
    "        self.model.eval()\n",
    "        val_losses = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for x, y in self.val_loader:\n",
    "                x, y = x.to(device), y.to(device)\n",
    "                y_class = (y.squeeze() < 0).long()\n",
    "                logits = self.model(x)[:, -1, :]\n",
    "                loss = self.loss_fn(logits, y_class)\n",
    "                val_losses.append(loss.item())\n",
    "\n",
    "        return sum(val_losses) / len(val_losses)\n",
    "\n",
    "    def plot_losses(self, smooth_window=1024):\n",
    "        \"\"\"\n",
    "        Plots training loss (smoothed) and validation loss.\n",
    "\n",
    "        Args:\n",
    "            smooth_window (int): Window size for moving average on train loss.\n",
    "        \"\"\"\n",
    "        plt.figure(figsize=(10, 4))\n",
    "\n",
    "        # Smooth train loss using moving average\n",
    "        if len(self.train_loss_steps) >= smooth_window:\n",
    "            kernel = np.ones(smooth_window) / smooth_window\n",
    "            smoothed_train = np.convolve(self.train_loss_steps, kernel, mode='valid')\n",
    "            plt.plot(smoothed_train, label=f\"Train Loss (smoothed, {smooth_window})\")\n",
    "        else:\n",
    "            plt.plot(self.train_loss_steps, label=\"Train Loss\")\n",
    "\n",
    "        # Plot val loss checkpoints\n",
    "        val_x = np.linspace(0, len(self.train_loss_steps), len(self.val_loss_checkpoints))\n",
    "        plt.plot(val_x, self.val_loss_checkpoints, label=\"Val Loss\")\n",
    "\n",
    "        plt.title(\"Training & Validation Loss\")\n",
    "        plt.xlabel(\"Train Steps\")\n",
    "        plt.ylabel(\"Loss\")\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2025-04-10T14:17:10.825856Z",
     "end_time": "2025-04-10T14:17:10.834347Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "trainer = Trainer(model, train_loader, val_loader, lr=1e-3)\n",
    "trainer.train(epochs=10)\n",
    "\n",
    "# access loss history\n",
    "train_loss = trainer.train_loss_history\n",
    "val_loss = trainer.val_loss_history\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.plot(trainer.train_loss_steps)\n",
    "plt.show()\n",
    "plt.plot(trainer.val_loss_checkpoints)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2025-04-10T14:23:55.251326Z",
     "end_time": "2025-04-10T14:23:55.312122Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "trainer.plot_losses(trainer)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2025-04-10T14:26:42.227253Z",
     "end_time": "2025-04-10T14:26:42.275399Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def plot_losses(self, smooth_window=64*4):\n",
    "        \"\"\"\n",
    "        Plots training loss (smoothed) and validation loss.\n",
    "\n",
    "        Args:\n",
    "            smooth_window (int): Window size for moving average on train loss.\n",
    "        \"\"\"\n",
    "        plt.figure(figsize=(10, 4))\n",
    "\n",
    "        # Smooth train loss using moving average\n",
    "        if len(self.train_loss_steps) >= smooth_window:\n",
    "            kernel = np.ones(smooth_window) / smooth_window\n",
    "            smoothed_train = np.convolve(self.train_loss_steps, kernel, mode='valid')\n",
    "            plt.plot(smoothed_train, label=f\"Train Loss (smoothed, {smooth_window})\")\n",
    "        else:\n",
    "            plt.plot(self.train_loss_steps, label=\"Train Loss\")\n",
    "\n",
    "        # Plot val loss checkpoints\n",
    "        val_x = np.linspace(0, len(self.train_loss_steps), len(self.val_loss_checkpoints))\n",
    "        plt.plot(val_x, self.val_loss_checkpoints, label=\"Val Loss\")\n",
    "\n",
    "        plt.title(\"Training & Validation Loss\")\n",
    "        plt.xlabel(\"Train Steps\")\n",
    "        plt.ylabel(\"Loss\")\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "trainer.plot_losses = plot_losses"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2025-04-10T14:26:37.020123Z",
     "end_time": "2025-04-10T14:26:37.052245Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ]
}
